import streamlit as st
import pandas as pd
import os
import plotly.express as px

# ==========================================
# 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡πÑ‡∏ï‡∏•‡πå (Font Sarabun)
# ==========================================
st.set_page_config(page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢", layout="wide")

st.markdown("""
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Sarabun:wght@300;400;700&display=swap" rel="stylesheet">
    <style>
        html, body, [class*="css"] { font-family: 'Sarabun', sans-serif; }
        .stMetric { background-color: #ffffff; padding: 15px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
        .main { background-color: #f8f9fa; }
        .stDataFrame { border-radius: 10px; }
    </style>
""", unsafe_allow_html=True)

MASTER_FILE = "masters.csv"
RESEARCH_FILE = "research.csv"

# ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô KPI
SCORE_MAP = {
    "TCI1": 0.8, "TCI2": 0.6,
    "Scopus Q1": 1.0, "Scopus Q2": 1.0, "Scopus Q3": 1.0, "Scopus Q4": 1.0,
}

# ==========================================
# 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏Å‡πâ Encoding)
# ==========================================
@st.cache_data(ttl=60)
def load_data(file_path, default_cols):
    if not os.path.exists(file_path):
        return pd.DataFrame(columns=default_cols)
    
    for enc in ["utf-8-sig", "cp874", "tis-620", "utf-8"]:
        try:
            df = pd.read_csv(file_path, encoding=enc)
            # ‡∏•‡∏ö‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô KeyError
            df.columns = df.columns.str.strip() 
            return df
        except (UnicodeDecodeError, Exception):
            continue
    
    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {file_path} ‡πÑ‡∏î‡πâ")
    return pd.DataFrame(columns=default_cols)

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df_master = load_data(MASTER_FILE, ["Name-surname", "‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£", "‡∏Ñ‡∏ì‡∏∞"])
df_research = load_data(RESEARCH_FILE, ["‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á", "‡∏õ‡∏µ", "‡∏ê‡∏≤‡∏ô‡∏ß‡∏≤‡∏£‡∏™‡∏≤‡∏£", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", "‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô"])

# ==========================================
# 3. ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏°‡∏ô‡∏π (Sidebar)
# ==========================================
with st.sidebar:
    st.title("üìå ‡πÄ‡∏°‡∏ô‡∏π‡∏´‡∏•‡∏±‡∏Å")
    menu = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠", ["‚úçÔ∏è ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏á‡∏≤‡∏ô", "üìä ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞ KPI", "‚öôÔ∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"])
    
    st.divider()
    if not df_research.empty:
        all_years = sorted(df_research["‡∏õ‡∏µ"].unique().tolist())
        year_option = st.selectbox("üîç ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏µ ‡∏û.‡∏®.", ["‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + [str(y) for y in all_years])
    else:
        year_option = "‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"

df_filtered = df_research.copy()
if year_option != "‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
    df_filtered = df_filtered[df_filtered["‡∏õ‡∏µ"] == int(year_option)]

# ==========================================
# 4. ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏á‡∏≤‡∏ô
# ==========================================
if menu == "‚úçÔ∏è ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏á‡∏≤‡∏ô":
    st.title("‚úçÔ∏è ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÉ‡∏´‡∏°‡πà")
    
    with st.form("research_form", clear_on_submit=True):
        col1, col2 = st.columns([3, 1])
        with col1: title = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢")
        with col2: year = st.number_input("‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡∏µ‡∏û‡∏¥‡∏°‡∏û‡πå (‡∏û.‡∏®.)", 2560, 2600, 2568)
        
        col3, col4 = st.columns(2)
        with col3: journal = st.selectbox("‡∏ê‡∏≤‡∏ô‡∏ß‡∏≤‡∏£‡∏™‡∏≤‡∏£", list(SCORE_MAP.keys()))
        with col4: 
            author_list = df_master["Name-surname"].dropna().unique().tolist() if "Name-surname" in df_master.columns else []
            authors = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô", author_list)

        if st.form_submit_button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"):
            if title and authors:
                new_rows = [{"‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á": title, "‡∏õ‡∏µ": year, "‡∏ê‡∏≤‡∏ô‡∏ß‡∏≤‡∏£‡∏™‡∏≤‡∏£": journal, 
                             "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô": SCORE_MAP[journal], "‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô": a} for a in authors]
                df_updated = pd.concat([df_research, pd.DataFrame(new_rows)], ignore_index=True)
                df_updated.to_csv(RESEARCH_FILE, index=False, encoding="utf-8-sig")
                st.success("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
                st.cache_data.clear()
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö")

# ==========================================
# 5. ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞ KPI
# ==========================================
elif menu == "üìä ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞ KPI":
    st.title(f"üìä ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô ({year_option})")
    
    if df_master.empty or "‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£" not in df_master.columns or "‡∏Ñ‡∏ì‡∏∞" not in df_master.columns:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ì‡∏∞‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå masters.csv ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á")
    else:
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£
        all_progs = df_master[["‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£", "‡∏Ñ‡∏ì‡∏∞"]].drop_duplicates().dropna()
        all_progs = all_progs[all_progs["‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£"] != "-"]
        
        faculty_counts = df_master.groupby("‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£")["Name-surname"].nunique().to_dict()

        # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏à‡∏±‡∏¢ (‡∏î‡∏∂‡∏á '‡∏Ñ‡∏ì‡∏∞' ‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Tab ‡∏£‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏∞)
        res_with_prog = df_filtered.merge(df_master[['Name-surname', '‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£', '‡∏Ñ‡∏ì‡∏∞']], 
                                         left_on="‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô", right_on="Name-surname", how="left")
        
        res_sum = res_with_prog.groupby("‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£")["‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô"].sum().reset_index()
        prog_report = all_progs.merge(res_sum, on="‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£", how="left").fillna(0)

        def calculate_kpi(row):
            prog = row["‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£"]
            score = row["‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô"]
            n_fac = faculty_counts.get(prog, 1)
            group_40 = ["G-Dip TH", "G-Dip Inter", "M. Ed-Admin", "M. Ed-LMS", "MBA", "MPH"]
            x_val = 60 if prog == "Ph.D-Admin" else (40 if prog in group_40 else 20)
            kpi = (((score / n_fac) * 100) / x_val) * 5
            return round(min(kpi, 5.0), 2)

        prog_report["‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"] = prog_report.apply(calculate_kpi, axis=1)

        t1, t2, t3 = st.tabs(["üéì ‡∏£‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£", "üë§ ‡∏£‡∏≤‡∏¢‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•", "üèõ ‡∏£‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏∞"])
        
        with t1:
            fig = px.bar(prog_report.sort_values("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"), x="‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô", y="‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£", 
                         color="‡∏Ñ‡∏ì‡∏∞", orientation='h', range_x=[0, 5.5], text="‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô")
            fig.add_vline(x=5, line_dash="dash", line_color="red")
            st.plotly_chart(fig, use_container_width=True)
            st.dataframe(prog_report, use_container_width=True)

        with t2:
            if not df_filtered.empty:
                p_report = df_filtered.groupby("‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô").agg({"‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á": "count", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô": "sum"}).reset_index()
                st.dataframe(p_report.sort_values("‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", ascending=False), use_container_width=True)
            else:
                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

        with t3:
            # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î KeyError: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
            if "‡∏Ñ‡∏ì‡∏∞" in res_with_prog.columns and "‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á" in res_with_prog.columns:
                fac_data = res_with_prog.drop_duplicates(subset=["‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á", "‡∏Ñ‡∏ì‡∏∞"])
                fac_sum = fac_data.groupby("‡∏Ñ‡∏ì‡∏∞")["‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô"].sum().reset_index()
                if not fac_sum.empty:
                    st.plotly_chart(px.pie(fac_sum, values='‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô', names='‡∏Ñ‡∏ì‡∏∞', title="‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ì‡∏∞"), use_container_width=True)
                    st.dataframe(fac_sum, use_container_width=True)
                else:
                    st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏∞")
            else:
                st.warning("‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏≤‡∏¢‡∏Ñ‡∏ì‡∏∞ (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '‡∏Ñ‡∏ì‡∏∞' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå masters.csv)")

# ==========================================
# 6. ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ==========================================
else:
    st.title("‚öôÔ∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    st.subheader("üóë ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢")
    if not df_research.empty:
        to_delete = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏ö", df_research["‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á"].unique())
        if st.button("‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö"):
            df_new = df_research[df_research["‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á"] != to_delete]
            df_new.to_csv(RESEARCH_FILE, index=False, encoding="utf-8-sig")
            st.success("‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            st.cache_data.clear()
            st.rerun()
    else:
        st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢")
    
    st.divider()
    st.subheader("üì• ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    if not df_research.empty:
        csv = df_research.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
        st.download_button("Download CSV", csv, "research_backup.csv", "text/csv")
